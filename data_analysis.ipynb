{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Phase 1: Data Analysis\n",
        "\n",
        "This notebook analyzes the structure of `Data/Molise.dta` to understand:\n",
        "- Available variables and their types\n",
        "- Temporal coverage\n",
        "- Region distribution\n",
        "- Worker classification fields\n",
        "- Outcome variables\n",
        "- Data quality issues\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Base directory: /Users/vittoriogaravelli/GitHub/GitHub/ERMDA-30464_GP\n",
            "Data directory: /Users/vittoriogaravelli/GitHub/GitHub/ERMDA-30464_GP/Data\n",
            "Data file exists: True\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pyreadstat\n",
        "import os\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Set up paths\n",
        "BASE_DIR = Path.cwd()\n",
        "DATA_DIR = BASE_DIR / \"Data\"\n",
        "OUT_DIR = BASE_DIR / \"out\"\n",
        "DERIVED_DIR = BASE_DIR / \"data\" / \"derived\"\n",
        "\n",
        "print(f\"Base directory: {BASE_DIR}\")\n",
        "print(f\"Data directory: {DATA_DIR}\")\n",
        "print(f\"Data file exists: {(DATA_DIR / 'Molise.dta').exists()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded Molise: 298,889 rows using pyreadstat\n",
            "Loaded Basilicata: 555,155 rows using pyreadstat\n",
            "Note: /Users/vittoriogaravelli/GitHub/GitHub/ERMDA-30464_GP/Data/Puglia.dta not found - skipping Puglia\n",
            "\n",
            "Combined dataset: 854,044 rows\n",
            "\n",
            "Dataset shape: (854044, 24)\n",
            "Memory usage: 541.06 MB\n"
          ]
        }
      ],
      "source": [
        "# Load the Stata files (Molise, Basilicata, and Puglia if available)\n",
        "molise_file = DATA_DIR / \"Molise.dta\"\n",
        "basilicata_file = DATA_DIR / \"Basilicata.dta\"\n",
        "puglia_file = DATA_DIR / \"Puglia.dta\"\n",
        "\n",
        "region_specs = [\n",
        "    (\"Molise\", molise_file, \"12\"),\n",
        "    (\"Basilicata\", basilicata_file, \"2\"),\n",
        "    (\"Puglia\", puglia_file, \"16\"),\n",
        "]\n",
        "\n",
        "dfs = []\n",
        "meta = None\n",
        "\n",
        "for region_name, path, region_code in region_specs:\n",
        "    if not path.exists():\n",
        "        print(f\"Note: {path} not found - skipping {region_name}\")\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        df_region, meta_region = pyreadstat.read_dta(path)\n",
        "        print(f\"Loaded {region_name}: {len(df_region):,} rows using pyreadstat\")\n",
        "    except Exception as e:\n",
        "        print(f\"pyreadstat failed for {region_name}: {e}, trying pandas...\")\n",
        "        df_region = pd.read_stata(path)\n",
        "        meta_region = None\n",
        "        print(f\"Loaded {region_name}: {len(df_region):,} rows using pandas\")\n",
        "\n",
        "    if meta is None and meta_region is not None:\n",
        "        meta = meta_region\n",
        "\n",
        "    df_region[\"region_res\"] = region_code\n",
        "    dfs.append(df_region)\n",
        "\n",
        "if not dfs:\n",
        "    raise FileNotFoundError(\"No data files found\")\n",
        "\n",
        "if len(dfs) > 1:\n",
        "    df = pd.concat(dfs, ignore_index=True)\n",
        "    print(f\"\\nCombined dataset: {len(df):,} rows\")\n",
        "else:\n",
        "    df = dfs[0]\n",
        "    print(f\"\\nSingle dataset: {len(df):,} rows\")\n",
        "\n",
        "print(f\"\\nDataset shape: {df.shape}\")\n",
        "print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "DATASET OVERVIEW\n",
            "================================================================================\n",
            "\n",
            "Shape: 854,044 rows × 24 columns\n",
            "\n",
            "Column names:\n",
            "['id_worker', 'year', 'year_birth', 'year_death', 'gender', 'region_res', 'year_pension', 'type', 'id_firm', 'date_start', 'date_end', 'working_weeks', 'wage', 'reason_end', 'part_time', 'part_time_fraction', 'contract_type', 'occupation', 'incentive_policy', 'firm_dimension', 'sector_2d', 'sector_12cat', 'firm_position', 'id_firm_parent']\n",
            "\n",
            "Data types:\n",
            "id_worker               int64\n",
            "year                    int64\n",
            "year_birth              int64\n",
            "year_death             object\n",
            "gender                  int64\n",
            "region_res             object\n",
            "year_pension           object\n",
            "type                    int64\n",
            "id_firm                object\n",
            "date_start             object\n",
            "date_end               object\n",
            "working_weeks          object\n",
            "wage                   object\n",
            "reason_end             object\n",
            "part_time              object\n",
            "part_time_fraction    float64\n",
            "contract_type          object\n",
            "occupation             object\n",
            "incentive_policy       object\n",
            "firm_dimension         object\n",
            "sector_2d              object\n",
            "sector_12cat           object\n",
            "firm_position          object\n",
            "id_firm_parent         object\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "# Basic info about the dataset\n",
        "print(\"=\" * 80)\n",
        "print(\"DATASET OVERVIEW\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"\\nShape: {df.shape[0]:,} rows × {df.shape[1]} columns\")\n",
        "print(f\"\\nColumn names:\")\n",
        "print(df.columns.tolist())\n",
        "print(f\"\\nData types:\")\n",
        "print(df.dtypes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "SAMPLE DATA (first 5 rows)\n",
            "================================================================================\n",
            "   id_worker  year  year_birth year_death  gender region_res year_pension  \\\n",
            "0       3052  2005        1981        NaN       0         12          NaN   \n",
            "1       3052  2002        1981        NaN       0         12          NaN   \n",
            "2       3052  2017        1981        NaN       0         12          NaN   \n",
            "3       3052  2016        1981        NaN       0         12          NaN   \n",
            "4       3052  2008        1981        NaN       0         12          NaN   \n",
            "\n",
            "   type  id_firm  date_start date_end working_weeks   wage reason_end  \\\n",
            "0     1  3583834  2005-12-27      NaN             1    300        NaN   \n",
            "1     4      NaN         NaN      NaN           NaN    NaN        NaN   \n",
            "2     1  2226770         NaN      NaN            52  19100        NaN   \n",
            "3     1  2226770         NaN      NaN            52  18100        NaN   \n",
            "4     1  5743594  2008-01-24      NaN            50  18700        NaN   \n",
            "\n",
            "  part_time  part_time_fraction contract_type occupation incentive_policy  \\\n",
            "0         0                 NaN             2          4                9   \n",
            "1       NaN                 NaN           NaN        NaN              NaN   \n",
            "2         0                 NaN             1          4               51   \n",
            "3         0                 NaN             1          4               51   \n",
            "4         0                 NaN             2          4              NaN   \n",
            "\n",
            "  firm_dimension sector_2d sector_12cat firm_position id_firm_parent  \n",
            "0             14        78            7             2        3583834  \n",
            "1            NaN       NaN          NaN           NaN            NaN  \n",
            "2              2        49           10             3        2226770  \n",
            "3              2        49           10             3        2226770  \n",
            "4             14        29            5             2        5743594  \n"
          ]
        }
      ],
      "source": [
        "# Display first few rows\n",
        "print(\"=\" * 80)\n",
        "print(\"SAMPLE DATA (first 5 rows)\")\n",
        "print(\"=\" * 80)\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "pd.set_option('display.max_colwidth', 50)\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basilicata filtered shape: (555155, 7)\n",
            "Molise filtered shape: (298889, 7)\n",
            "Warning: no rows found for region code 16 (puglia)\n"
          ]
        }
      ],
      "source": [
        "# Filter dataset for Basilicata, Molise, and Puglia with selected columns\n",
        "columns_to_keep = [\"id_worker\", \"year\", \"type\", \"wage\", \"contract_type\", \"sector_2d\", \"region_res\"]\n",
        "\n",
        "if \"region_res\" not in df.columns:\n",
        "    raise KeyError(\"Column 'region_res' not found in dataframe\")\n",
        "\n",
        "region_filters = {\n",
        "    \"basilicata\": \"2\",\n",
        "    \"molise\": \"12\",\n",
        "    \"puglia\": \"16\",\n",
        "}\n",
        "\n",
        "filtered_subsets = {}\n",
        "region_series = df[\"region_res\"].astype(str)\n",
        "\n",
        "for region_name, region_code in region_filters.items():\n",
        "    mask = region_series == region_code\n",
        "    if mask.any():\n",
        "        subset = df.loc[mask, columns_to_keep].copy()\n",
        "        filtered_subsets[region_name] = subset\n",
        "        print(f\"{region_name.title()} filtered shape: {subset.shape}\")\n",
        "    else:\n",
        "        filtered_subsets[region_name] = pd.DataFrame(columns=columns_to_keep)\n",
        "        print(f\"Warning: no rows found for region code {region_code} ({region_name})\")\n",
        "\n",
        "basilicata_filtered = filtered_subsets[\"basilicata\"]\n",
        "molise_filtered = filtered_subsets[\"molise\"]\n",
        "puglia_filtered = filtered_subsets[\"puglia\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Type value counts (overall):\n",
            "type\n",
            "1    354897\n",
            "2     52545\n",
            "3     48611\n",
            "4    397991\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Type labels from metadata:\n",
            "{1: 'Private employees', 2: 'Public employees', 3: 'Self-employed', 4: 'Non employed'}\n"
          ]
        }
      ],
      "source": [
        "# Inspect mapping of 'type' to identify non-employed code\n",
        "print(\"Type value counts (overall):\")\n",
        "print(df[\"type\"].value_counts().sort_index())\n",
        "\n",
        "if 'type' in meta.variable_value_labels:\n",
        "    print(\"\\nType labels from metadata:\")\n",
        "    print(meta.variable_value_labels['type'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "basilicata employed share: 0.5292\n",
            "molise employed share: 0.5428\n",
            "puglia employed share: n/a (no data)\n"
          ]
        }
      ],
      "source": [
        "# Create binary employed indicator\n",
        "regional_sets = {\n",
        "    \"basilicata\": basilicata_filtered,\n",
        "    \"molise\": molise_filtered,\n",
        "    \"puglia\": puglia_filtered,\n",
        "}\n",
        "\n",
        "for region_name, subset in regional_sets.items():\n",
        "    if subset.empty:\n",
        "        print(f\"{region_name} employed share: n/a (no data)\")\n",
        "        continue\n",
        "    wage_positive = pd.to_numeric(subset[\"wage\"], errors=\"coerce\").fillna(0) > 0\n",
        "    type_non_employed = subset[\"type\"].eq(4)\n",
        "    subset[\"employed\"] = (wage_positive | ~type_non_employed).astype(\"Int8\")\n",
        "    print(f\"{region_name} employed share: {subset['employed'].mean():.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "basilicata: retained 292,964 rows for 9,875 eligible workers\n",
            "molise: retained 160,799 rows for 5,431 eligible workers\n",
            "puglia: retained 0 rows (no data)\n"
          ]
        }
      ],
      "source": [
        "# Retain only workers employed in 1999, 2000, or 2001\n",
        "COHORT_YEARS = {1999, 2000, 2001}\n",
        "filtered_results = {}\n",
        "\n",
        "for region_name, subset in {\n",
        "    \"basilicata\": basilicata_filtered,\n",
        "    \"molise\": molise_filtered,\n",
        "    \"puglia\": puglia_filtered,\n",
        "}.items():\n",
        "    if subset.empty:\n",
        "        filtered_results[region_name] = subset\n",
        "        print(f\"{region_name}: retained 0 rows (no data)\")\n",
        "        continue\n",
        "\n",
        "    eligible_workers = subset.loc[\n",
        "        subset[\"year\"].isin(COHORT_YEARS) & subset[\"employed\"].eq(1),\n",
        "        \"id_worker\"\n",
        "    ].unique()\n",
        "    filtered_subset = subset[subset[\"id_worker\"].isin(eligible_workers)].copy()\n",
        "    filtered_results[region_name] = filtered_subset\n",
        "    print(\n",
        "        f\"{region_name}: retained {len(filtered_subset):,} rows for\"\n",
        "        f\" {len(eligible_workers):,} eligible workers\"\n",
        "    )\n",
        "\n",
        "basilicata_filtered = filtered_results[\"basilicata\"]\n",
        "molise_filtered = filtered_results[\"molise\"]\n",
        "puglia_filtered = filtered_results[\"puglia\"]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "After year restriction:\n",
            "  Basilicata: 75,905 rows\n",
            "  Molise: 41,610 rows\n",
            "  Puglia: 0 rows\n"
          ]
        }
      ],
      "source": [
        "YEAR_WINDOW = range(1999, 2007)\n",
        "\n",
        "restricted_sets = {}\n",
        "for region_name, subset in {\n",
        "    \"Basilicata\": basilicata_filtered,\n",
        "    \"Molise\": molise_filtered,\n",
        "    \"Puglia\": puglia_filtered,\n",
        "}.items():\n",
        "    restricted = subset[subset[\"year\"].isin(YEAR_WINDOW)].copy()\n",
        "    restricted_sets[region_name.lower()] = restricted\n",
        "\n",
        "print(\"After year restriction:\")\n",
        "for region_name, subset in restricted_sets.items():\n",
        "    print(f\"  {region_name.title()}: {len(subset):,} rows\")\n",
        "\n",
        "basilicata_filtered = restricted_sets[\"basilicata\"]\n",
        "molise_filtered = restricted_sets[\"molise\"]\n",
        "puglia_filtered = restricted_sets[\"puglia\"]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wage min/max by region:\n",
            "  Basilicata: min=0.00, max=163,300.00\n",
            "  Molise: min=0.00, max=175,300.00\n",
            "  Puglia: n/a\n"
          ]
        }
      ],
      "source": [
        "# Wage range diagnostics\n",
        "print(\"Wage min/max by region:\")\n",
        "for region_name, subset in {\n",
        "    \"Basilicata\": basilicata_filtered,\n",
        "    \"Molise\": molise_filtered,\n",
        "    \"Puglia\": puglia_filtered,\n",
        "}.items():\n",
        "    if subset.empty or \"wage\" not in subset.columns:\n",
        "        print(f\"  {region_name}: n/a\")\n",
        "        continue\n",
        "    wages = pd.to_numeric(subset[\"wage\"], errors=\"coerce\")\n",
        "    print(\n",
        "        f\"  {region_name}: min={wages.min(skipna=True):,.2f},\"\n",
        "        f\" max={wages.max(skipna=True):,.2f}\"\n",
        "    )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wage diagnostics before income_category creation:\n",
            "  Basilicata:\n",
            "    Total rows: 75,905\n",
            "    Non-null wages: 62,426\n",
            "    Null wages: 13,479\n",
            "    Wages > 0: 62,343\n",
            "    Wages == 0: 83\n",
            "    Min wage: 0.00\n",
            "    Max wage: 163,300.00\n",
            "    Mean wage: 15,826.99\n",
            "\n",
            "  Molise:\n",
            "    Total rows: 41,610\n",
            "    Non-null wages: 34,302\n",
            "    Null wages: 7,308\n",
            "    Wages > 0: 34,210\n",
            "    Wages == 0: 92\n",
            "    Min wage: 0.00\n",
            "    Max wage: 175,300.00\n",
            "    Mean wage: 16,172.84\n",
            "\n",
            "  Puglia: n/a\n"
          ]
        }
      ],
      "source": [
        "# Diagnostic: Check wage values before creating income_category\n",
        "print(\"Wage diagnostics before income_category creation:\")\n",
        "for region_name, subset in {\n",
        "    \"Basilicata\": basilicata_filtered,\n",
        "    \"Molise\": molise_filtered,\n",
        "    \"Puglia\": puglia_filtered,\n",
        "}.items():\n",
        "    if subset.empty or \"wage\" not in subset.columns:\n",
        "        print(f\"  {region_name}: n/a\")\n",
        "        continue\n",
        "    wages = pd.to_numeric(subset[\"wage\"], errors=\"coerce\")\n",
        "    print(f\"  {region_name}:\")\n",
        "    print(f\"    Total rows: {len(subset):,}\")\n",
        "    print(f\"    Non-null wages: {wages.notna().sum():,}\")\n",
        "    print(f\"    Null wages: {wages.isna().sum():,}\")\n",
        "    print(f\"    Wages > 0: {(wages > 0).sum():,}\")\n",
        "    print(f\"    Wages == 0: {(wages == 0).sum():,}\")\n",
        "    if wages.notna().any():\n",
        "        print(f\"    Min wage: {wages.min():,.2f}\")\n",
        "        print(f\"    Max wage: {wages.max():,.2f}\")\n",
        "        print(f\"    Mean wage: {wages.mean():,.2f}\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Basilicata: income_category distribution:\n",
            "income_category\n",
            "1    56580\n",
            "2     4713\n",
            "3     1133\n",
            "Name: count, dtype: Int64\n",
            "  Basilicata: NaN count in income_category: 13,479\n",
            "\n",
            "  Molise: income_category distribution:\n",
            "income_category\n",
            "1    30860\n",
            "2     2836\n",
            "3      606\n",
            "Name: count, dtype: Int64\n",
            "  Molise: NaN count in income_category: 7,308\n",
            "\n",
            "  Puglia: n/a (no data or no wage column)\n"
          ]
        }
      ],
      "source": [
        "# Add income_category column based on wage\n",
        "for region_name, subset in {\n",
        "    \"Basilicata\": basilicata_filtered,\n",
        "    \"Molise\": molise_filtered,\n",
        "    \"Puglia\": puglia_filtered,\n",
        "}.items():\n",
        "    if subset.empty or \"wage\" not in subset.columns:\n",
        "        print(f\"  {region_name}: n/a (no data or no wage column)\")\n",
        "        continue\n",
        "    \n",
        "    # Convert wage to numeric\n",
        "    wages = pd.to_numeric(subset[\"wage\"], errors=\"coerce\")\n",
        "    \n",
        "    # Initialize income_category column with NaN\n",
        "    income_cat = pd.Series(index=subset.index, dtype=\"Int8\")\n",
        "    \n",
        "    # Only assign categories for non-NaN wages\n",
        "    valid_mask = wages.notna()\n",
        "    if valid_mask.any():\n",
        "        valid_wages = wages[valid_mask]\n",
        "        \n",
        "        # Create income category column (using numeric codes: 1=low, 2=medium, 3=high)\n",
        "        conditions = [\n",
        "            valid_wages < 28000,\n",
        "            (valid_wages >= 28000) & (valid_wages <= 50000),\n",
        "            valid_wages > 50000\n",
        "        ]\n",
        "        choices = [1, 2, 3]  # 1=low income, 2=medium, 3=high\n",
        "        \n",
        "        # Assign categories only for valid wages\n",
        "        income_cat[valid_mask] = np.select(conditions, choices, default=None)\n",
        "    \n",
        "    # Assign to the subset DataFrame\n",
        "    subset[\"income_category\"] = income_cat.astype(\"Int8\")\n",
        "    \n",
        "    print(f\"  {region_name}: income_category distribution:\")\n",
        "    print(subset[\"income_category\"].value_counts().sort_index())\n",
        "    print(f\"  {region_name}: NaN count in income_category: {subset['income_category'].isna().sum():,}\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved Basilicata filtered data to /Users/vittoriogaravelli/GitHub/GitHub/ERMDA-30464_GP/data/derived/basilicata_filtered.dta\n",
            "Saved Molise filtered data to /Users/vittoriogaravelli/GitHub/GitHub/ERMDA-30464_GP/data/derived/molise_filtered.dta\n",
            "Skipping puglia export (no data)\n"
          ]
        }
      ],
      "source": [
        "# Save filtered datasets\n",
        "DERIVED_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "output_specs = {\n",
        "    \"basilicata\": (basilicata_filtered, DERIVED_DIR / \"basilicata_filtered.dta\"),\n",
        "    \"molise\": (molise_filtered, DERIVED_DIR / \"molise_filtered.dta\"),\n",
        "    \"puglia\": (puglia_filtered, DERIVED_DIR / \"puglia_filtered.dta\"),\n",
        "}\n",
        "\n",
        "for region_name, (subset, path) in output_specs.items():\n",
        "    if subset.empty:\n",
        "        print(f\"Skipping {region_name} export (no data)\")\n",
        "        continue\n",
        "    subset.convert_dtypes().to_stata(path, write_index=False, version=118)\n",
        "    print(f\"Saved {region_name.title()} filtered data to {path}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "data_analysis",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
