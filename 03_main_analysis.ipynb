{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Phase 3: Main Analysis\n",
        "\n",
        "This notebook implements the full analysis pipeline:\n",
        "1. Data preparation\n",
        "2. Baseline DiD estimation\n",
        "3. DDD by worker type\n",
        "4. Event-study analysis\n",
        "5. Three environments analysis\n",
        "6. Robustness checks\n",
        "7. Heterogeneity analysis\n",
        "8. Diagnostics\n",
        "9. Report generation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "import sys\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Add src to path\n",
        "BASE_DIR = Path.cwd()\n",
        "SRC_DIR = BASE_DIR / \"src\"\n",
        "sys.path.insert(0, str(SRC_DIR))\n",
        "\n",
        "# Import our modules\n",
        "from io import load_raw, write_parquet\n",
        "from build import assemble_panel\n",
        "from models import did, ddd_worker_type, event_study\n",
        "from plots import plot_event\n",
        "from export import write_table\n",
        "from diagnostics import pretrend_test, cell_counts\n",
        "\n",
        "# Set up directories\n",
        "OUT_DIR = BASE_DIR / \"out\"\n",
        "DERIVED_DIR = BASE_DIR / \"data\" / \"derived\"\n",
        "TABLES_DIR = OUT_DIR / \"tables\"\n",
        "FIGURES_DIR = OUT_DIR / \"figures\"\n",
        "REPORT_DIR = OUT_DIR / \"report\"\n",
        "DIAGNOSTICS_DIR = OUT_DIR / \"diagnostics\"\n",
        "\n",
        "for d in [DERIVED_DIR, TABLES_DIR, FIGURES_DIR, REPORT_DIR, DIAGNOSTICS_DIR]:\n",
        "    d.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Set random seed\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"Setup complete!\")\n",
        "print(f\"Output directories created\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.1 Data Preparation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load raw data\n",
        "print(\"=\" * 80)\n",
        "print(\"LOADING RAW DATA\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "df_raw, meta = load_raw()\n",
        "print(f\"\\nRaw data: {len(df_raw):,} rows × {len(df_raw.columns)} columns\")\n",
        "print(f\"\\nYear range: {df_raw['year'].min()} - {df_raw['year'].max()}\")\n",
        "print(f\"\\nRegion distribution:\")\n",
        "print(df_raw['region_res'].value_counts())\n",
        "\n",
        "# Check if we have Basilicata (region code 2)\n",
        "has_basilicata = (df_raw['region_res'] == '2').sum() > 0\n",
        "print(f\"\\nHas Basilicata data: {has_basilicata}\")\n",
        "\n",
        "if not has_basilicata:\n",
        "    print(\"\\nWARNING: No Basilicata data found. Will use within-Molise variation only.\")\n",
        "    print(\"Alternative: Use Puglia (14) or another control region if available.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Assemble analysis-ready panel\n",
        "print(\"=\" * 80)\n",
        "print(\"ASSEMBLING ANALYSIS PANEL\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "panel = assemble_panel(df_raw, meta)\n",
        "print(f\"\\nPanel: {len(panel):,} rows\")\n",
        "print(f\"Years: {panel['year'].min()} - {panel['year'].max()}\")\n",
        "print(f\"\\nWorker types:\")\n",
        "print(panel['worker_type'].value_counts())\n",
        "print(f\"\\nMolise vs Basilicata:\")\n",
        "print(panel['molise_res'].value_counts())\n",
        "print(f\"\\nPre vs Post:\")\n",
        "print(panel['post'].value_counts())\n",
        "\n",
        "# Save panel\n",
        "write_parquet(panel, DERIVED_DIR / \"analysis_ready.parquet\")\n",
        "print(f\"\\nPanel saved to {DERIVED_DIR / 'analysis_ready.parquet'}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check data availability by cell\n",
        "print(\"=\" * 80)\n",
        "print(\"DATA AVAILABILITY BY CELL\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "cell_counts_df = cell_counts(panel, ['molise_res', 'worker_type', 'year'])\n",
        "print(cell_counts_df.pivot_table(index=['molise_res', 'worker_type'], columns='year', values='count', fill_value=0))\n",
        "\n",
        "# Check for cells with < 50 observations\n",
        "low_count_cells = cell_counts_df[cell_counts_df['count'] < 50]\n",
        "if len(low_count_cells) > 0:\n",
        "    print(f\"\\nWARNING: {len(low_count_cells)} cells have < 50 observations\")\n",
        "    print(low_count_cells.head(10))\n",
        "else:\n",
        "    print(\"\\nAll cells have >= 50 observations\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.2 Baseline DiD Estimation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define outcomes to estimate\n",
        "outcomes = ['emp_prob', 'earnings_asinh', 'wage_asinh', 'contract_perm']\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"BASELINE DiD ESTIMATION\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "baseline_results = {}\n",
        "\n",
        "for outcome in outcomes:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Outcome: {outcome}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    try:\n",
        "        result = did(panel, outcome=outcome)\n",
        "        baseline_results[outcome] = result\n",
        "        \n",
        "        # Print summary\n",
        "        print(f\"\\nTreatment effect (β): {result.params['treat']:.4f}\")\n",
        "        print(f\"Standard error: {result.std_errors['treat']:.4f}\")\n",
        "        print(f\"P-value: {result.pvalues['treat']:.4f}\")\n",
        "        print(f\"95% CI: [{result.params['treat'] - 1.96*result.std_errors['treat']:.4f}, \"\n",
        "              f\"{result.params['treat'] + 1.96*result.std_errors['treat']:.4f}]\")\n",
        "        print(f\"N observations: {result.nobs:,}\")\n",
        "        \n",
        "        # Export table\n",
        "        write_table(result, TABLES_DIR / f\"baseline_did_{outcome}\", format='both')\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Error estimating {outcome}: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.3 DDD by Worker Type\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 80)\n",
        "print(\"DDD BY WORKER TYPE\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "ddd_results = {}\n",
        "\n",
        "# Estimate for key outcomes\n",
        "ddd_outcomes = ['emp_prob', 'earnings_asinh']\n",
        "\n",
        "for outcome in ddd_outcomes:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Outcome: {outcome}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    try:\n",
        "        result = ddd_worker_type(panel, outcome=outcome)\n",
        "        ddd_results[outcome] = result\n",
        "        \n",
        "        # Extract key coefficients\n",
        "        if 'treat_private' in result.params.index:\n",
        "            theta = result.params['treat_private']\n",
        "            theta_se = result.std_errors['treat_private']\n",
        "            print(f\"\\nθ (Private vs Public): {theta:.4f} (SE: {theta_se:.4f}, p={result.pvalues['treat_private']:.4f})\")\n",
        "        \n",
        "        if 'treat_self' in result.params.index:\n",
        "            phi = result.params['treat_self']\n",
        "            phi_se = result.std_errors['treat_self']\n",
        "            print(f\"φ (Self vs Public): {phi:.4f} (SE: {phi_se:.4f}, p={result.pvalues['treat_self']:.4f})\")\n",
        "        \n",
        "        print(f\"N observations: {result.nobs:,}\")\n",
        "        \n",
        "        # Export table\n",
        "        write_table(result, TABLES_DIR / f\"ddd_{outcome}\", format='both')\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Error estimating {outcome}: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.4 Event Study\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 80)\n",
        "print(\"EVENT-STUDY ANALYSIS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "event_results = {}\n",
        "\n",
        "# Estimate event studies\n",
        "event_outcomes = ['emp_prob', 'earnings_asinh']\n",
        "\n",
        "for outcome in event_outcomes:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Outcome: {outcome}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    try:\n",
        "        # Pooled event study\n",
        "        result_pooled = event_study(panel, outcome=outcome, by_type=False)\n",
        "        event_results[f\"{outcome}_pooled\"] = result_pooled\n",
        "        \n",
        "        # Plot\n",
        "        plot_event(result_pooled, \n",
        "                  title=f\"Event Study: {outcome}\",\n",
        "                  outfile=FIGURES_DIR / f\"fig_event_{outcome}.png\",\n",
        "                  by_type=False)\n",
        "        \n",
        "        # By worker type\n",
        "        result_by_type = event_study(panel, outcome=outcome, by_type=True)\n",
        "        event_results[f\"{outcome}_by_type\"] = result_by_type\n",
        "        \n",
        "        # Plot by type\n",
        "        plot_event(result_by_type,\n",
        "                  title=f\"Event Study: {outcome} by Worker Type\",\n",
        "                  outfile=FIGURES_DIR / f\"fig_event_{outcome}_bytype.png\",\n",
        "                  by_type=True)\n",
        "        \n",
        "        # Test parallel trends\n",
        "        pretrend = pretrend_test(result_pooled)\n",
        "        print(f\"\\nParallel trends test (pre-period):\")\n",
        "        print(f\"  Test statistic: {pretrend.get('test_stat', 'N/A'):.4f}\")\n",
        "        print(f\"  P-value: {pretrend.get('p_value', 'N/A'):.4f}\")\n",
        "        \n",
        "        # Save results\n",
        "        result_pooled.to_csv(TABLES_DIR / f\"event_study_{outcome}.csv\", index=False)\n",
        "        result_by_type.to_csv(TABLES_DIR / f\"event_study_{outcome}_bytype.csv\", index=False)\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Error estimating event study for {outcome}: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.5 Three Environments Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Three environments: Panel A (within Molise), Panel B (within Basilicata), Panel C (DDD)\n",
        "print(\"=\" * 80)\n",
        "print(\"THREE ENVIRONMENTS ANALYSIS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# This analysis compares private vs public within each region\n",
        "three_env_results = {}\n",
        "\n",
        "# Focus on earnings_asinh\n",
        "outcome = 'earnings_asinh'\n",
        "\n",
        "try:\n",
        "    # Panel A: Within Molise (private vs public)\n",
        "    molise_data = panel[panel['molise_res'] == 1].copy()\n",
        "    if len(molise_data) > 0:\n",
        "        # Create private dummy\n",
        "        molise_data['private_dummy'] = (molise_data['worker_type'] == 'private').astype(int)\n",
        "        molise_data['post_private'] = molise_data['post'] * molise_data['private_dummy']\n",
        "        \n",
        "        # Simple DiD within Molise\n",
        "        molise_data_idx = molise_data.set_index(['id_worker', 'year'])\n",
        "        y_molise = molise_data_idx[outcome]\n",
        "        X_molise = molise_data_idx[['post_private', 'post', 'private_dummy']].copy()\n",
        "        X_molise = sm.add_constant(X_molise)\n",
        "        \n",
        "        from linearmodels import PanelOLS\n",
        "        import statsmodels.api as sm\n",
        "        mod_molise = PanelOLS(y_molise, X_molise, entity_effects=True, time_effects=True)\n",
        "        result_molise = mod_molise.fit(cov_type='clustered', cluster_entity=True)\n",
        "        \n",
        "        panel_a_coef = result_molise.params.get('post_private', np.nan)\n",
        "        three_env_results['Panel_A_Molise'] = panel_a_coef\n",
        "        print(f\"Panel A (Within Molise): {panel_a_coef:.4f}\")\n",
        "    \n",
        "    # Panel B: Within Basilicata (if available)\n",
        "    basilicata_data = panel[panel['molise_res'] == 0].copy()\n",
        "    if len(basilicata_data) > 0:\n",
        "        basilicata_data['private_dummy'] = (basilicata_data['worker_type'] == 'private').astype(int)\n",
        "        basilicata_data['post_private'] = basilicata_data['post'] * basilicata_data['private_dummy']\n",
        "        \n",
        "        basilicata_data_idx = basilicata_data.set_index(['id_worker', 'year'])\n",
        "        y_bas = basilicata_data_idx[outcome]\n",
        "        X_bas = basilicata_data_idx[['post_private', 'post', 'private_dummy']].copy()\n",
        "        X_bas = sm.add_constant(X_bas)\n",
        "        \n",
        "        mod_bas = PanelOLS(y_bas, X_bas, entity_effects=True, time_effects=True)\n",
        "        result_bas = mod_bas.fit(cov_type='clustered', cluster_entity=True)\n",
        "        \n",
        "        panel_b_coef = result_bas.params.get('post_private', np.nan)\n",
        "        three_env_results['Panel_B_Basilicata'] = panel_b_coef\n",
        "        print(f\"Panel B (Within Basilicata): {panel_b_coef:.4f}\")\n",
        "    else:\n",
        "        print(\"Panel B: No Basilicata data available\")\n",
        "        three_env_results['Panel_B_Basilicata'] = np.nan\n",
        "    \n",
        "    # Panel C: DDD (already estimated above)\n",
        "    if outcome in ddd_results:\n",
        "        ddd_result = ddd_results[outcome]\n",
        "        if 'treat_private' in ddd_result.params.index:\n",
        "            panel_c_coef = ddd_result.params['treat_private']\n",
        "            three_env_results['Panel_C_DDD'] = panel_c_coef\n",
        "            print(f\"Panel C (DDD): {panel_c_coef:.4f}\")\n",
        "    \n",
        "    # Create summary table\n",
        "    three_env_table = pd.DataFrame({\n",
        "        'Panel': ['A: Within Molise', 'B: Within Basilicata', 'C: DDD'],\n",
        "        'Coefficient': [\n",
        "            three_env_results.get('Panel_A_Molise', np.nan),\n",
        "            three_env_results.get('Panel_B_Basilicata', np.nan),\n",
        "            three_env_results.get('Panel_C_DDD', np.nan)\n",
        "        ]\n",
        "    })\n",
        "    \n",
        "    three_env_table.to_csv(TABLES_DIR / \"table_three_env.csv\", index=False)\n",
        "    print(f\"\\nThree environments table saved to {TABLES_DIR / 'table_three_env.csv'}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"Error in three environments analysis: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 80)\n",
        "print(\"ROBUSTNESS CHECKS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "robustness_results = {}\n",
        "baseline_coef = baseline_results.get('earnings_asinh', None)\n",
        "baseline_beta = baseline_coef.params['treat'] if baseline_coef else None\n",
        "\n",
        "# 1. Exclude border municipalities (if flagged)\n",
        "if 'is_border_municipality' in panel.columns:\n",
        "    panel_no_border = panel[~panel['is_border_municipality']].copy()\n",
        "    try:\n",
        "        result = did(panel_no_border, outcome='earnings_asinh')\n",
        "        robustness_results['no_border'] = {\n",
        "            'coef': result.params['treat'],\n",
        "            'se': result.std_errors['treat'],\n",
        "            'delta': result.params['treat'] - baseline_beta if baseline_beta else np.nan\n",
        "        }\n",
        "        print(f\"No border municipalities: β = {result.params['treat']:.4f}\")\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "# 2. Balanced panel only\n",
        "panel_balanced = panel[panel['is_balanced_97_07']].copy()\n",
        "try:\n",
        "    result = did(panel_balanced, outcome='earnings_asinh')\n",
        "    robustness_results['balanced'] = {\n",
        "        'coef': result.params['treat'],\n",
        "        'se': result.std_errors['treat'],\n",
        "        'delta': result.params['treat'] - baseline_beta if baseline_beta else np.nan\n",
        "    }\n",
        "    print(f\"Balanced panel: β = {result.params['treat']:.4f}\")\n",
        "except Exception as e:\n",
        "    print(f\"Balanced panel failed: {e}\")\n",
        "\n",
        "# 3. Alternative post window: 2003-2005\n",
        "panel_short_post = panel[(panel['year'] < 2002) | (panel['year'].between(2003, 2005))].copy()\n",
        "panel_short_post['post'] = (panel_short_post['year'] >= 2003).astype(int)\n",
        "panel_short_post['treat'] = panel_short_post['molise_res'] * panel_short_post['post']\n",
        "try:\n",
        "    result = did(panel_short_post, outcome='earnings_asinh')\n",
        "    robustness_results['post_2003_2005'] = {\n",
        "        'coef': result.params['treat'],\n",
        "        'se': result.std_errors['treat'],\n",
        "        'delta': result.params['treat'] - baseline_beta if baseline_beta else np.nan\n",
        "    }\n",
        "    print(f\"Post window 2003-2005: β = {result.params['treat']:.4f}\")\n",
        "except Exception as e:\n",
        "    print(f\"Short post window failed: {e}\")\n",
        "\n",
        "# 4. Include 2002 with shock indicator\n",
        "panel_with_2002 = panel.copy()\n",
        "panel_with_2002 = df_raw[(df_raw['year'].between(1997, 2007)) & \n",
        "                         (df_raw['region_res'].isin(['12', '2']))].copy()\n",
        "# Re-assemble with 2002\n",
        "from build import construct_worker_type, make_outcomes, make_flags\n",
        "panel_with_2002 = panel_with_2002[panel_with_2002['type'].isin([1, 2, 3])].copy()\n",
        "panel_with_2002['worker_type'] = construct_worker_type(panel_with_2002)\n",
        "panel_with_2002['molise_res'] = (panel_with_2002['region_res'] == '12').astype(int)\n",
        "panel_with_2002['post'] = (panel_with_2002['year'] >= 2003).astype(int)\n",
        "panel_with_2002['shock2002'] = (panel_with_2002['year'] == 2002).astype(int)\n",
        "panel_with_2002['treat'] = panel_with_2002['molise_res'] * panel_with_2002['post']\n",
        "outcomes_2002 = make_outcomes(panel_with_2002)\n",
        "for col in outcomes_2002.columns:\n",
        "    panel_with_2002[col] = outcomes_2002[col]\n",
        "\n",
        "try:\n",
        "    # Estimate with shock2002 indicator\n",
        "    data_2002 = panel_with_2002.set_index(['id_worker', 'year'])\n",
        "    y_2002 = data_2002['earnings_asinh']\n",
        "    X_2002 = data_2002[['treat', 'shock2002']].copy()\n",
        "    X_2002 = sm.add_constant(X_2002)\n",
        "    mod_2002 = PanelOLS(y_2002, X_2002, entity_effects=True, time_effects=True)\n",
        "    result_2002 = mod_2002.fit(cov_type='clustered', cluster_entity=True)\n",
        "    robustness_results['with_2002'] = {\n",
        "        'coef': result_2002.params['treat'],\n",
        "        'se': result_2002.std_errors['treat'],\n",
        "        'delta': result_2002.params['treat'] - baseline_beta if baseline_beta else np.nan\n",
        "    }\n",
        "    print(f\"With 2002 indicator: β = {result_2002.params['treat']:.4f}\")\n",
        "except Exception as e:\n",
        "    print(f\"With 2002 failed: {e}\")\n",
        "\n",
        "# Create robustness summary\n",
        "robustness_summary = pd.DataFrame(robustness_results).T\n",
        "robustness_summary.index.name = 'Specification'\n",
        "robustness_summary.to_csv(TABLES_DIR / \"robustness_index.csv\")\n",
        "print(f\"\\nRobustness summary saved to {TABLES_DIR / 'robustness_index.csv'}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 80)\n",
        "print(\"HETEROGENEITY ANALYSIS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "heterogeneity_results = {}\n",
        "outcome = 'earnings_asinh'\n",
        "\n",
        "# 1. By gender × worker type\n",
        "print(\"\\nBy Gender × Worker Type:\")\n",
        "for gender_val in [0, 1]:\n",
        "    gender_label = 'Male' if gender_val == 0 else 'Female'\n",
        "    for worker_type in ['public', 'private', 'self']:\n",
        "        subset = panel[(panel['gender'] == gender_val) & (panel['worker_type'] == worker_type)].copy()\n",
        "        if len(subset) > 100:  # Minimum sample size\n",
        "            try:\n",
        "                result = did(subset, outcome=outcome)\n",
        "                coef = result.params['treat']\n",
        "                heterogeneity_results[f'gender_{gender_label}_type_{worker_type}'] = coef\n",
        "                print(f\"  {gender_label} × {worker_type}: {coef:.4f}\")\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "# 2. By age groups\n",
        "print(\"\\nBy Age Groups:\")\n",
        "if 'age' in panel.columns:\n",
        "    panel['age_group'] = pd.cut(panel['age'], bins=[0, 30, 50, 100], labels=['<30', '30-49', '50+'])\n",
        "    for age_group in ['<30', '30-49', '50+']:\n",
        "        subset = panel[panel['age_group'] == age_group].copy()\n",
        "        if len(subset) > 100:\n",
        "            try:\n",
        "                result = did(subset, outcome=outcome)\n",
        "                coef = result.params['treat']\n",
        "                heterogeneity_results[f'age_{age_group}'] = coef\n",
        "                print(f\"  {age_group}: {coef:.4f}\")\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "# 3. By sector (construction vs other)\n",
        "print(\"\\nBy Sector:\")\n",
        "if 'sector_12cat' in panel.columns:\n",
        "    # Construction = 2\n",
        "    panel['is_construction'] = (panel['sector_12cat'] == 2).astype(int)\n",
        "    for sector_label, sector_val in [('Construction', 1), ('Other', 0)]:\n",
        "        subset = panel[panel['is_construction'] == sector_val].copy()\n",
        "        if len(subset) > 100:\n",
        "            try:\n",
        "                result = did(subset, outcome=outcome)\n",
        "                coef = result.params['treat']\n",
        "                heterogeneity_results[f'sector_{sector_label}'] = coef\n",
        "                print(f\"  {sector_label}: {coef:.4f}\")\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "# Save heterogeneity results\n",
        "heterogeneity_df = pd.DataFrame({\n",
        "    'Group': list(heterogeneity_results.keys()),\n",
        "    'Coefficient': list(heterogeneity_results.values())\n",
        "})\n",
        "heterogeneity_df.to_csv(TABLES_DIR / \"heterogeneity_grids\" / \"all_dimensions.csv\", index=False)\n",
        "print(f\"\\nHeterogeneity results saved\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.8 Diagnostics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 80)\n",
        "print(\"DIAGNOSTICS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# 1. Parallel trends test (already done in event study, but summarize)\n",
        "print(\"\\nParallel Trends Tests:\")\n",
        "for outcome in ['emp_prob', 'earnings_asinh']:\n",
        "    if f\"{outcome}_pooled\" in event_results:\n",
        "        pretrend = pretrend_test(event_results[f\"{outcome}_pooled\"])\n",
        "        print(f\"  {outcome}: p-value = {pretrend.get('p_value', 'N/A'):.4f}\")\n",
        "\n",
        "# 2. Cell counts\n",
        "print(\"\\nCell Counts (Region × Type × Year):\")\n",
        "cell_counts_diag = cell_counts(panel, ['molise_res', 'worker_type', 'year'])\n",
        "print(cell_counts_diag.head(20))\n",
        "cell_counts_diag.to_csv(DIAGNOSTICS_DIR / \"cell_counts.csv\", index=False)\n",
        "\n",
        "# 3. Missingness audit\n",
        "print(\"\\nMissingness Audit:\")\n",
        "missing_audit = pd.DataFrame({\n",
        "    'Variable': panel.columns,\n",
        "    'Missing_Count': [panel[col].isna().sum() for col in panel.columns],\n",
        "    'Missing_Pct': [panel[col].isna().sum() / len(panel) * 100 for col in panel.columns]\n",
        "})\n",
        "missing_audit = missing_audit[missing_audit['Missing_Count'] > 0].sort_values('Missing_Count', ascending=False)\n",
        "print(missing_audit.head(10))\n",
        "missing_audit.to_csv(DIAGNOSTICS_DIR / \"missingness_audit.csv\", index=False)\n",
        "\n",
        "# 4. Winsorization info\n",
        "print(\"\\nWinsorization:\")\n",
        "if 'earnings_asinh' in panel.columns:\n",
        "    # Check how many were winsorized (would need to track this in build.py)\n",
        "    print(\"  Earnings winsorized at p1-p99 (tracked in variable construction)\")\n",
        "\n",
        "print(f\"\\nDiagnostics saved to {DIAGNOSTICS_DIR}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.9 Report Generation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 80)\n",
        "print(\"GENERATING REPORT\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Copy all figures to report directory\n",
        "import shutil\n",
        "figures_report_dir = REPORT_DIR / \"_figures\"\n",
        "figures_report_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "for fig_file in FIGURES_DIR.glob(\"*.png\"):\n",
        "    shutil.copy(fig_file, figures_report_dir / fig_file.name)\n",
        "    print(f\"Copied {fig_file.name}\")\n",
        "\n",
        "# Copy all tables to report directory\n",
        "tables_report_dir = REPORT_DIR / \"_tables\"\n",
        "tables_report_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "for table_file in TABLES_DIR.glob(\"*.csv\"):\n",
        "    shutil.copy(table_file, tables_report_dir / table_file.name)\n",
        "    print(f\"Copied {table_file.name}\")\n",
        "\n",
        "# Create README\n",
        "readme_content = f\"\"\"# Molise 2002 Earthquake Labor-Market Analysis\n",
        "\n",
        "## Model Formulas\n",
        "\n",
        "### Baseline DiD\n",
        "Y_{{i r t}} = α + β(molise_res × post) + γ_i + λ_t + ε_{{i r t}}\n",
        "\n",
        "- FE: individual (γ_i) and year (λ_t)\n",
        "- Clustered SE: person_id\n",
        "- Outcomes: emp_prob, earnings_asinh, wage_asinh, contract_perm\n",
        "\n",
        "### DDD by Worker Type\n",
        "Y_{{i s r t}} = α + θ(molise_res × post × private) + φ(molise_res × post × self) + \n",
        "                all two-way interactions + γ_i + λ_t + μ_s + ε_{{i s r t}}\n",
        "\n",
        "- FE: individual, year, worker_type\n",
        "- θ: Private vs Public\n",
        "- φ: Self vs Public\n",
        "\n",
        "### Event Study\n",
        "Y_{{i r t}} = α + Σ_{{k≠-1}} β_k [1{{event_time = k}} × molise_res] + γ_i + λ_t + ε_{{i r t}}\n",
        "\n",
        "- Reference period: k = -1 (year 2001)\n",
        "- Event time range: k ∈ [-5, +5], excluding 0 (2002)\n",
        "\n",
        "## Variable Construction\n",
        "\n",
        "- **worker_type**: Constructed from 'type' field (1=Private, 2=Public, 3=Self, 4=Non-employed)\n",
        "- **molise_res**: 1 if region_res == 12 (Molise), 0 if region_res == 2 (Basilicata), fixed by pre-period\n",
        "- **post**: 1 if year >= 2003\n",
        "- **treat**: molise_res × post\n",
        "- **event_time**: year - 2002\n",
        "- **earnings_asinh**: asinh(earnings_annualized), winsorized at p1-p99\n",
        "- **emp_prob**: 1 if employed (has wage or working_weeks > 0)\n",
        "\n",
        "## Dataset Lineage\n",
        "\n",
        "- Raw data: Data/Molise.dta\n",
        "- Processed panel: data/derived/analysis_ready.parquet\n",
        "- Analysis period: 1997-2001 (pre) and 2003-2007 (post), excluding 2002\n",
        "- Regions: Molise (12) and Basilicata (2) if available\n",
        "\n",
        "## Clustering\n",
        "\n",
        "Standard errors clustered by person_id (entity-level clustering).\n",
        "\n",
        "## Sample Definitions\n",
        "\n",
        "- **Balanced panel**: Present in all years 1997-2007 (excluding 2002)\n",
        "- **Stayers**: No inter-municipality moves (if municipality data available)\n",
        "- **Border municipalities**: Flagged if on region border (requires additional data)\n",
        "\n",
        "Generated: {pd.Timestamp.now()}\n",
        "\"\"\"\n",
        "\n",
        "with open(REPORT_DIR / \"README.md\", \"w\") as f:\n",
        "    f.write(readme_content)\n",
        "print(f\"\\nREADME saved to {REPORT_DIR / 'README.md'}\")\n",
        "\n",
        "# Create session info\n",
        "import platform\n",
        "import sys\n",
        "session_info = f\"\"\"Session Information\n",
        "==================\n",
        "\n",
        "Python version: {sys.version}\n",
        "Platform: {platform.platform()}\n",
        "Date: {pd.Timestamp.now()}\n",
        "\n",
        "Package versions:\n",
        "- pandas: {pd.__version__}\n",
        "- numpy: {np.__version__}\n",
        "- linearmodels: {__import__('linearmodels').__version__ if hasattr(__import__('linearmodels'), '__version__') else 'N/A'}\n",
        "- matplotlib: {plt.matplotlib.__version__}\n",
        "\"\"\"\n",
        "\n",
        "with open(REPORT_DIR / \"session_info.txt\", \"w\") as f:\n",
        "    f.write(session_info)\n",
        "print(f\"Session info saved to {REPORT_DIR / 'session_info.txt'}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"ANALYSIS COMPLETE!\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"\\nAll outputs saved to:\")\n",
        "print(f\"  Tables: {TABLES_DIR}\")\n",
        "print(f\"  Figures: {FIGURES_DIR}\")\n",
        "print(f\"  Report: {REPORT_DIR}\")\n",
        "print(f\"  Diagnostics: {DIAGNOSTICS_DIR}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
